{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn_Modelling\n",
    "#### Reference: https://www.kaggle.com/aakash50897/churn-modellingcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "5       8  113755.78              2          1               0   \n",
       "6       7       0.00              2          1               1   \n",
       "7       4  115046.74              4          1               0   \n",
       "8       4  142051.07              2          0               1   \n",
       "9       2  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hong\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Hong\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:] # Avoiding dummy variable trap!\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def build_classifier():\n",
    "    # Initializing the ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer with dropout\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    # classifier.add(Dropout(rate = 0.2))\n",
    "\n",
    "    # Adding the second hidden layer with dropout\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    # classifier.add(Dropout(rate = 0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = build_classifier()\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/300\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.5402 - acc: 0.7960 - val_loss: 0.4403 - val_acc: 0.7975\n",
      "Epoch 2/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.4346 - acc: 0.7960 - val_loss: 0.4261 - val_acc: 0.7975\n",
      "Epoch 3/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.4258 - acc: 0.7960 - val_loss: 0.4195 - val_acc: 0.7975\n",
      "Epoch 4/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.4199 - acc: 0.8072 - val_loss: 0.4159 - val_acc: 0.8360\n",
      "Epoch 5/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.4151 - acc: 0.8291 - val_loss: 0.4092 - val_acc: 0.8345\n",
      "Epoch 6/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4112 - acc: 0.8326 - val_loss: 0.4045 - val_acc: 0.8420\n",
      "Epoch 7/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.4086 - acc: 0.8336 - val_loss: 0.4027 - val_acc: 0.8440\n",
      "Epoch 8/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.4065 - acc: 0.8350 - val_loss: 0.4024 - val_acc: 0.8420\n",
      "Epoch 9/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.4047 - acc: 0.8345 - val_loss: 0.4008 - val_acc: 0.8420\n",
      "Epoch 10/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.4037 - acc: 0.8351 - val_loss: 0.3993 - val_acc: 0.8405\n",
      "Epoch 11/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.4025 - acc: 0.8359 - val_loss: 0.3977 - val_acc: 0.8455\n",
      "Epoch 12/300\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.4013 - acc: 0.8329 - val_loss: 0.3982 - val_acc: 0.8430\n",
      "Epoch 13/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.4008 - acc: 0.8354 - val_loss: 0.3967 - val_acc: 0.8445\n",
      "Epoch 14/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4001 - acc: 0.8350 - val_loss: 0.3958 - val_acc: 0.8430\n",
      "Epoch 15/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3994 - acc: 0.8351 - val_loss: 0.3953 - val_acc: 0.8445\n",
      "Epoch 16/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3985 - acc: 0.8350 - val_loss: 0.3972 - val_acc: 0.8410\n",
      "Epoch 17/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3985 - acc: 0.8356 - val_loss: 0.3939 - val_acc: 0.8435\n",
      "Epoch 18/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3979 - acc: 0.8354 - val_loss: 0.3957 - val_acc: 0.8420\n",
      "Epoch 19/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3976 - acc: 0.8372 - val_loss: 0.3964 - val_acc: 0.8415\n",
      "Epoch 20/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3975 - acc: 0.8354 - val_loss: 0.3937 - val_acc: 0.8440\n",
      "Epoch 21/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3969 - acc: 0.835 - 0s 51us/step - loss: 0.3970 - acc: 0.8355 - val_loss: 0.3953 - val_acc: 0.8415\n",
      "Epoch 22/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3973 - acc: 0.8344 - val_loss: 0.3950 - val_acc: 0.8425\n",
      "Epoch 23/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3964 - acc: 0.8370 - val_loss: 0.3964 - val_acc: 0.8445\n",
      "Epoch 24/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3965 - acc: 0.8357 - val_loss: 0.3945 - val_acc: 0.8405\n",
      "Epoch 25/300\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3963 - acc: 0.8361 - val_loss: 0.3940 - val_acc: 0.8425\n",
      "Epoch 26/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3965 - acc: 0.8369 - val_loss: 0.3949 - val_acc: 0.8420\n",
      "Epoch 27/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3961 - acc: 0.8357 - val_loss: 0.3955 - val_acc: 0.8420\n",
      "Epoch 28/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3961 - acc: 0.8356 - val_loss: 0.3965 - val_acc: 0.8430\n",
      "Epoch 29/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3958 - acc: 0.8346 - val_loss: 0.3962 - val_acc: 0.8405\n",
      "Epoch 30/300\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3958 - acc: 0.8350 - val_loss: 0.3948 - val_acc: 0.8425\n",
      "Epoch 31/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3953 - acc: 0.8352 - val_loss: 0.3972 - val_acc: 0.8410\n",
      "Epoch 32/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3955 - acc: 0.8362 - val_loss: 0.3976 - val_acc: 0.8430\n",
      "Epoch 33/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3953 - acc: 0.8360 - val_loss: 0.3938 - val_acc: 0.8415\n",
      "Epoch 34/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3949 - acc: 0.8346 - val_loss: 0.3934 - val_acc: 0.8415\n",
      "Epoch 35/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3951 - acc: 0.8349 - val_loss: 0.3971 - val_acc: 0.8425\n",
      "Epoch 36/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3952 - acc: 0.8357 - val_loss: 0.3961 - val_acc: 0.8405\n",
      "Epoch 37/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3948 - acc: 0.8371 - val_loss: 0.3973 - val_acc: 0.8400\n",
      "Epoch 38/300\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3949 - acc: 0.8344 - val_loss: 0.3976 - val_acc: 0.8415\n",
      "Epoch 39/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3948 - acc: 0.8346 - val_loss: 0.3959 - val_acc: 0.8410\n",
      "Epoch 40/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3944 - acc: 0.8355 - val_loss: 0.3992 - val_acc: 0.8405\n",
      "Epoch 41/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3942 - acc: 0.8355 - val_loss: 0.3953 - val_acc: 0.8410\n",
      "Epoch 42/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3944 - acc: 0.8344 - val_loss: 0.3958 - val_acc: 0.8415\n",
      "Epoch 43/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3938 - acc: 0.8357 - val_loss: 0.3964 - val_acc: 0.8440\n",
      "Epoch 44/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3944 - acc: 0.8351 - val_loss: 0.3945 - val_acc: 0.8425\n",
      "Epoch 45/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3942 - acc: 0.8352 - val_loss: 0.3957 - val_acc: 0.8425\n",
      "Epoch 46/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3941 - acc: 0.8350 - val_loss: 0.3957 - val_acc: 0.8420\n",
      "Epoch 47/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3941 - acc: 0.8332 - val_loss: 0.3961 - val_acc: 0.8430\n",
      "Epoch 48/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3941 - acc: 0.8350 - val_loss: 0.3959 - val_acc: 0.8415\n",
      "Epoch 49/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3938 - acc: 0.8361 - val_loss: 0.3975 - val_acc: 0.8425\n",
      "Epoch 50/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3939 - acc: 0.8350 - val_loss: 0.3950 - val_acc: 0.8425\n",
      "Epoch 51/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3938 - acc: 0.8355 - val_loss: 0.3957 - val_acc: 0.8435\n",
      "Epoch 52/300\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3940 - acc: 0.8350 - val_loss: 0.3951 - val_acc: 0.8410\n",
      "Epoch 53/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3943 - acc: 0.8347 - val_loss: 0.3940 - val_acc: 0.8445\n",
      "Epoch 54/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3936 - acc: 0.8369 - val_loss: 0.3955 - val_acc: 0.8425\n",
      "Epoch 55/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3937 - acc: 0.8369 - val_loss: 0.3955 - val_acc: 0.8445\n",
      "Epoch 56/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3935 - acc: 0.8360 - val_loss: 0.3952 - val_acc: 0.8430\n",
      "Epoch 57/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3937 - acc: 0.8349 - val_loss: 0.3948 - val_acc: 0.8435\n",
      "Epoch 58/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3931 - acc: 0.8357 - val_loss: 0.3963 - val_acc: 0.8435\n",
      "Epoch 59/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3933 - acc: 0.8352 - val_loss: 0.3960 - val_acc: 0.8470\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3935 - acc: 0.8345 - val_loss: 0.3944 - val_acc: 0.8450\n",
      "Epoch 61/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3937 - acc: 0.8364 - val_loss: 0.3962 - val_acc: 0.8460\n",
      "Epoch 62/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3930 - acc: 0.8367 - val_loss: 0.3975 - val_acc: 0.8440\n",
      "Epoch 63/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3930 - acc: 0.8354 - val_loss: 0.3947 - val_acc: 0.8450\n",
      "Epoch 64/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3936 - acc: 0.8367 - val_loss: 0.3946 - val_acc: 0.8450\n",
      "Epoch 65/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3931 - acc: 0.8364 - val_loss: 0.3975 - val_acc: 0.8460\n",
      "Epoch 66/300\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3927 - acc: 0.8352 - val_loss: 0.3938 - val_acc: 0.8455\n",
      "Epoch 67/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3935 - acc: 0.8371 - val_loss: 0.3951 - val_acc: 0.8440\n",
      "Epoch 68/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3932 - acc: 0.8355 - val_loss: 0.3949 - val_acc: 0.8445\n",
      "Epoch 69/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3931 - acc: 0.8364 - val_loss: 0.3954 - val_acc: 0.8440\n",
      "Epoch 70/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3924 - acc: 0.8345 - val_loss: 0.3957 - val_acc: 0.8455\n",
      "Epoch 71/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3928 - acc: 0.8361 - val_loss: 0.3950 - val_acc: 0.8445\n",
      "Epoch 72/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3935 - acc: 0.8352 - val_loss: 0.3933 - val_acc: 0.8450\n",
      "Epoch 73/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3930 - acc: 0.8359 - val_loss: 0.3965 - val_acc: 0.8440\n",
      "Epoch 74/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3927 - acc: 0.8360 - val_loss: 0.3953 - val_acc: 0.8440\n",
      "Epoch 75/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3933 - acc: 0.8370 - val_loss: 0.3960 - val_acc: 0.8440\n",
      "Epoch 76/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3928 - acc: 0.8345 - val_loss: 0.3959 - val_acc: 0.8455\n",
      "Epoch 77/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3929 - acc: 0.8376 - val_loss: 0.3949 - val_acc: 0.8440\n",
      "Epoch 78/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3927 - acc: 0.8364 - val_loss: 0.3966 - val_acc: 0.8425\n",
      "Epoch 79/300\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3929 - acc: 0.8367 - val_loss: 0.3948 - val_acc: 0.8430\n",
      "Epoch 80/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3929 - acc: 0.8361 - val_loss: 0.3956 - val_acc: 0.8440\n",
      "Epoch 81/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3930 - acc: 0.8361 - val_loss: 0.3941 - val_acc: 0.8435\n",
      "Epoch 82/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3929 - acc: 0.8375 - val_loss: 0.3938 - val_acc: 0.8435\n",
      "Epoch 83/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3929 - acc: 0.8350 - val_loss: 0.3960 - val_acc: 0.8445\n",
      "Epoch 84/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3924 - acc: 0.8369 - val_loss: 0.3941 - val_acc: 0.8435\n",
      "Epoch 85/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3932 - acc: 0.8350 - val_loss: 0.3939 - val_acc: 0.8460\n",
      "Epoch 86/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3922 - acc: 0.8379 - val_loss: 0.3960 - val_acc: 0.8450\n",
      "Epoch 87/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3928 - acc: 0.8366 - val_loss: 0.3936 - val_acc: 0.8480\n",
      "Epoch 88/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3930 - acc: 0.8370 - val_loss: 0.3935 - val_acc: 0.8440\n",
      "Epoch 89/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3920 - acc: 0.8382 - val_loss: 0.3958 - val_acc: 0.8450\n",
      "Epoch 90/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3930 - acc: 0.8384 - val_loss: 0.3946 - val_acc: 0.8475\n",
      "Epoch 91/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3924 - acc: 0.8366 - val_loss: 0.3951 - val_acc: 0.8460\n",
      "Epoch 92/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3923 - acc: 0.8379 - val_loss: 0.3944 - val_acc: 0.8420\n",
      "Epoch 93/300\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3927 - acc: 0.8380 - val_loss: 0.3925 - val_acc: 0.8480\n",
      "Epoch 94/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3954 - acc: 0.836 - 0s 42us/step - loss: 0.3924 - acc: 0.8384 - val_loss: 0.3932 - val_acc: 0.8435\n",
      "Epoch 95/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3920 - acc: 0.8370 - val_loss: 0.3932 - val_acc: 0.8455\n",
      "Epoch 96/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3924 - acc: 0.8379 - val_loss: 0.3936 - val_acc: 0.8445\n",
      "Epoch 97/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3926 - acc: 0.8370 - val_loss: 0.3936 - val_acc: 0.8475\n",
      "Epoch 98/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3919 - acc: 0.8371 - val_loss: 0.3931 - val_acc: 0.8450\n",
      "Epoch 99/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3926 - acc: 0.8375 - val_loss: 0.3930 - val_acc: 0.8445\n",
      "Epoch 100/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3920 - acc: 0.8377 - val_loss: 0.3929 - val_acc: 0.8465\n",
      "Epoch 101/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3919 - acc: 0.8365 - val_loss: 0.3934 - val_acc: 0.8455\n",
      "Epoch 102/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3921 - acc: 0.8381 - val_loss: 0.3927 - val_acc: 0.8450\n",
      "Epoch 103/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3918 - acc: 0.8375 - val_loss: 0.3926 - val_acc: 0.8455\n",
      "Epoch 104/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3914 - acc: 0.8389 - val_loss: 0.3919 - val_acc: 0.8425\n",
      "Epoch 105/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3915 - acc: 0.8382 - val_loss: 0.3914 - val_acc: 0.8435\n",
      "Epoch 106/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3912 - acc: 0.8390 - val_loss: 0.3920 - val_acc: 0.8435\n",
      "Epoch 107/300\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3907 - acc: 0.8387 - val_loss: 0.3909 - val_acc: 0.8450\n",
      "Epoch 108/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3902 - acc: 0.8404 - val_loss: 0.3907 - val_acc: 0.8465\n",
      "Epoch 109/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3898 - acc: 0.8395 - val_loss: 0.3893 - val_acc: 0.8440\n",
      "Epoch 110/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3887 - acc: 0.8399 - val_loss: 0.3889 - val_acc: 0.8420\n",
      "Epoch 111/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3879 - acc: 0.8397 - val_loss: 0.3871 - val_acc: 0.8410\n",
      "Epoch 112/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3871 - acc: 0.8400 - val_loss: 0.3867 - val_acc: 0.8420\n",
      "Epoch 113/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3857 - acc: 0.8421 - val_loss: 0.3865 - val_acc: 0.8455\n",
      "Epoch 114/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3836 - acc: 0.8414 - val_loss: 0.3871 - val_acc: 0.8415\n",
      "Epoch 115/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3810 - acc: 0.8411 - val_loss: 0.3805 - val_acc: 0.8435\n",
      "Epoch 116/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3790 - acc: 0.8419 - val_loss: 0.3783 - val_acc: 0.8470\n",
      "Epoch 117/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3765 - acc: 0.8427 - val_loss: 0.3767 - val_acc: 0.8435\n",
      "Epoch 118/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3743 - acc: 0.8425 - val_loss: 0.3807 - val_acc: 0.8410\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3716 - acc: 0.8431 - val_loss: 0.3702 - val_acc: 0.8435\n",
      "Epoch 120/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3686 - acc: 0.8470 - val_loss: 0.3669 - val_acc: 0.8475\n",
      "Epoch 121/300\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3662 - acc: 0.8482 - val_loss: 0.3631 - val_acc: 0.8470\n",
      "Epoch 122/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3631 - acc: 0.8470 - val_loss: 0.3592 - val_acc: 0.8505\n",
      "Epoch 123/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3600 - acc: 0.8511 - val_loss: 0.3590 - val_acc: 0.8520\n",
      "Epoch 124/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3591 - acc: 0.8499 - val_loss: 0.3578 - val_acc: 0.8475\n",
      "Epoch 125/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3559 - acc: 0.8539 - val_loss: 0.3556 - val_acc: 0.8475\n",
      "Epoch 126/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3553 - acc: 0.8522 - val_loss: 0.3541 - val_acc: 0.8500\n",
      "Epoch 127/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3538 - acc: 0.8540 - val_loss: 0.3531 - val_acc: 0.8495\n",
      "Epoch 128/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3526 - acc: 0.8537 - val_loss: 0.3513 - val_acc: 0.8535\n",
      "Epoch 129/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3518 - acc: 0.8526 - val_loss: 0.3529 - val_acc: 0.8500\n",
      "Epoch 130/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3512 - acc: 0.8565 - val_loss: 0.3496 - val_acc: 0.8525\n",
      "Epoch 131/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3499 - acc: 0.8544 - val_loss: 0.3467 - val_acc: 0.8525\n",
      "Epoch 132/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3491 - acc: 0.8580 - val_loss: 0.3524 - val_acc: 0.8495\n",
      "Epoch 133/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3484 - acc: 0.8560 - val_loss: 0.3461 - val_acc: 0.8510s - loss: 0.3486 - acc: 0.856\n",
      "Epoch 134/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3476 - acc: 0.8554 - val_loss: 0.3478 - val_acc: 0.8475\n",
      "Epoch 135/300\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3467 - acc: 0.8569 - val_loss: 0.3488 - val_acc: 0.8515\n",
      "Epoch 136/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3467 - acc: 0.8570 - val_loss: 0.3438 - val_acc: 0.8490\n",
      "Epoch 137/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3458 - acc: 0.8610 - val_loss: 0.3437 - val_acc: 0.8515\n",
      "Epoch 138/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3463 - acc: 0.8569 - val_loss: 0.3447 - val_acc: 0.8500\n",
      "Epoch 139/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3448 - acc: 0.8595 - val_loss: 0.3461 - val_acc: 0.8530\n",
      "Epoch 140/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3449 - acc: 0.8587 - val_loss: 0.3449 - val_acc: 0.8540\n",
      "Epoch 141/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3442 - acc: 0.8599 - val_loss: 0.3486 - val_acc: 0.8480\n",
      "Epoch 142/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3440 - acc: 0.8575 - val_loss: 0.3427 - val_acc: 0.8520\n",
      "Epoch 143/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3440 - acc: 0.8599 - val_loss: 0.3432 - val_acc: 0.8585\n",
      "Epoch 144/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3440 - acc: 0.8601 - val_loss: 0.3421 - val_acc: 0.8520\n",
      "Epoch 145/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3439 - acc: 0.8560 - val_loss: 0.3429 - val_acc: 0.8575\n",
      "Epoch 146/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3431 - acc: 0.8595 - val_loss: 0.3415 - val_acc: 0.8525\n",
      "Epoch 147/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3429 - acc: 0.8591 - val_loss: 0.3431 - val_acc: 0.8535\n",
      "Epoch 148/300\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3432 - acc: 0.8601 - val_loss: 0.3420 - val_acc: 0.8515\n",
      "Epoch 149/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3425 - acc: 0.8602 - val_loss: 0.3436 - val_acc: 0.8505\n",
      "Epoch 150/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3416 - acc: 0.8610 - val_loss: 0.3423 - val_acc: 0.8530\n",
      "Epoch 151/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3418 - acc: 0.8606 - val_loss: 0.3420 - val_acc: 0.8555\n",
      "Epoch 152/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3409 - acc: 0.8612 - val_loss: 0.3494 - val_acc: 0.8500\n",
      "Epoch 153/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3410 - acc: 0.8607 - val_loss: 0.3379 - val_acc: 0.8560\n",
      "Epoch 154/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3411 - acc: 0.8610 - val_loss: 0.3393 - val_acc: 0.8550\n",
      "Epoch 155/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3407 - acc: 0.8610 - val_loss: 0.3388 - val_acc: 0.8510\n",
      "Epoch 156/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3411 - acc: 0.8601 - val_loss: 0.3370 - val_acc: 0.8555\n",
      "Epoch 157/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3396 - acc: 0.8607 - val_loss: 0.3429 - val_acc: 0.8500\n",
      "Epoch 158/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3401 - acc: 0.8599 - val_loss: 0.3427 - val_acc: 0.8520\n",
      "Epoch 159/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3396 - acc: 0.8604 - val_loss: 0.3416 - val_acc: 0.8525\n",
      "Epoch 160/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3400 - acc: 0.8585 - val_loss: 0.3361 - val_acc: 0.8590\n",
      "Epoch 161/300\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3401 - acc: 0.8600 - val_loss: 0.3386 - val_acc: 0.8540\n",
      "Epoch 162/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3398 - acc: 0.8605 - val_loss: 0.3416 - val_acc: 0.8510\n",
      "Epoch 163/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3395 - acc: 0.8591 - val_loss: 0.3383 - val_acc: 0.8560\n",
      "Epoch 164/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3390 - acc: 0.8625 - val_loss: 0.3380 - val_acc: 0.8545\n",
      "Epoch 165/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3388 - acc: 0.8599 - val_loss: 0.3373 - val_acc: 0.8560\n",
      "Epoch 166/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3393 - acc: 0.8611 - val_loss: 0.3363 - val_acc: 0.8575\n",
      "Epoch 167/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3386 - acc: 0.8630 - val_loss: 0.3369 - val_acc: 0.8525\n",
      "Epoch 168/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3394 - acc: 0.8605 - val_loss: 0.3377 - val_acc: 0.8610\n",
      "Epoch 169/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3392 - acc: 0.8595 - val_loss: 0.3388 - val_acc: 0.8550\n",
      "Epoch 170/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3379 - acc: 0.8610 - val_loss: 0.3395 - val_acc: 0.8555\n",
      "Epoch 171/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3384 - acc: 0.8614 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 172/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3384 - acc: 0.8609 - val_loss: 0.3393 - val_acc: 0.8570\n",
      "Epoch 173/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3381 - acc: 0.8612 - val_loss: 0.3418 - val_acc: 0.8540\n",
      "Epoch 174/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3384 - acc: 0.8592 - val_loss: 0.3358 - val_acc: 0.8545\n",
      "Epoch 175/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3382 - acc: 0.8597 - val_loss: 0.3349 - val_acc: 0.8575\n",
      "Epoch 176/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3390 - acc: 0.8595 - val_loss: 0.3390 - val_acc: 0.8535\n",
      "Epoch 177/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3379 - acc: 0.8622 - val_loss: 0.3358 - val_acc: 0.8550\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3372 - acc: 0.8626 - val_loss: 0.3382 - val_acc: 0.8565\n",
      "Epoch 179/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3379 - acc: 0.8627 - val_loss: 0.3383 - val_acc: 0.8535\n",
      "Epoch 180/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3373 - acc: 0.8605 - val_loss: 0.3345 - val_acc: 0.8580\n",
      "Epoch 181/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3386 - acc: 0.8617 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 182/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3381 - acc: 0.8616 - val_loss: 0.3357 - val_acc: 0.8605\n",
      "Epoch 183/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3379 - acc: 0.860 - 0s 44us/step - loss: 0.3377 - acc: 0.8607 - val_loss: 0.3357 - val_acc: 0.8545\n",
      "Epoch 184/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3367 - acc: 0.8620 - val_loss: 0.3376 - val_acc: 0.8580\n",
      "Epoch 185/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3376 - acc: 0.8596 - val_loss: 0.3396 - val_acc: 0.8545\n",
      "Epoch 186/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3384 - acc: 0.8619 - val_loss: 0.3426 - val_acc: 0.8515\n",
      "Epoch 187/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3370 - acc: 0.8627 - val_loss: 0.3368 - val_acc: 0.8530\n",
      "Epoch 188/300\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3374 - acc: 0.8616 - val_loss: 0.3451 - val_acc: 0.8510\n",
      "Epoch 189/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3372 - acc: 0.8595 - val_loss: 0.3391 - val_acc: 0.8510\n",
      "Epoch 190/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3373 - acc: 0.8600 - val_loss: 0.3419 - val_acc: 0.8570\n",
      "Epoch 191/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3375 - acc: 0.8622 - val_loss: 0.3394 - val_acc: 0.8500\n",
      "Epoch 192/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3359 - acc: 0.8635 - val_loss: 0.3372 - val_acc: 0.8565\n",
      "Epoch 193/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3368 - acc: 0.8606 - val_loss: 0.3339 - val_acc: 0.8585\n",
      "Epoch 194/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3367 - acc: 0.8607 - val_loss: 0.3329 - val_acc: 0.8560\n",
      "Epoch 195/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3371 - acc: 0.8620 - val_loss: 0.3375 - val_acc: 0.8510\n",
      "Epoch 196/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3374 - acc: 0.861 - 0s 50us/step - loss: 0.3377 - acc: 0.8611 - val_loss: 0.3380 - val_acc: 0.8545\n",
      "Epoch 197/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3366 - acc: 0.8600 - val_loss: 0.3339 - val_acc: 0.8615\n",
      "Epoch 198/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3362 - acc: 0.8616 - val_loss: 0.3351 - val_acc: 0.8540\n",
      "Epoch 199/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3367 - acc: 0.8627 - val_loss: 0.3337 - val_acc: 0.8615\n",
      "Epoch 200/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3376 - acc: 0.8609 - val_loss: 0.3388 - val_acc: 0.8535\n",
      "Epoch 201/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3345 - acc: 0.860 - 0s 50us/step - loss: 0.3371 - acc: 0.8590 - val_loss: 0.3398 - val_acc: 0.8515\n",
      "Epoch 202/300\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3366 - acc: 0.8622 - val_loss: 0.3372 - val_acc: 0.8580\n",
      "Epoch 203/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3367 - acc: 0.8600 - val_loss: 0.3368 - val_acc: 0.8545\n",
      "Epoch 204/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3366 - acc: 0.8601 - val_loss: 0.3316 - val_acc: 0.8590\n",
      "Epoch 205/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3365 - acc: 0.8626 - val_loss: 0.3388 - val_acc: 0.8550\n",
      "Epoch 206/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3364 - acc: 0.8637 - val_loss: 0.3348 - val_acc: 0.8620\n",
      "Epoch 207/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3374 - acc: 0.8595 - val_loss: 0.3390 - val_acc: 0.8555\n",
      "Epoch 208/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3360 - acc: 0.8629 - val_loss: 0.3359 - val_acc: 0.8565\n",
      "Epoch 209/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3370 - acc: 0.8604 - val_loss: 0.3334 - val_acc: 0.8605\n",
      "Epoch 210/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3363 - acc: 0.8619 - val_loss: 0.3360 - val_acc: 0.8555: 0s - loss: 0.3351 - acc: 0\n",
      "Epoch 211/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3364 - acc: 0.8624 - val_loss: 0.3422 - val_acc: 0.8515\n",
      "Epoch 212/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3358 - acc: 0.8624 - val_loss: 0.3366 - val_acc: 0.8585\n",
      "Epoch 213/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3356 - acc: 0.8617 - val_loss: 0.3382 - val_acc: 0.8515\n",
      "Epoch 214/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3365 - acc: 0.8625 - val_loss: 0.3329 - val_acc: 0.8580\n",
      "Epoch 215/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3362 - acc: 0.8627 - val_loss: 0.3363 - val_acc: 0.8595\n",
      "Epoch 216/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3368 - acc: 0.8626 - val_loss: 0.3336 - val_acc: 0.8565\n",
      "Epoch 217/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3358 - acc: 0.8627 - val_loss: 0.3341 - val_acc: 0.8590\n",
      "Epoch 218/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3360 - acc: 0.8614 - val_loss: 0.3326 - val_acc: 0.8565\n",
      "Epoch 219/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3355 - acc: 0.8615 - val_loss: 0.3344 - val_acc: 0.8635\n",
      "Epoch 220/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3368 - acc: 0.8612 - val_loss: 0.3373 - val_acc: 0.8570\n",
      "Epoch 221/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3365 - acc: 0.8614 - val_loss: 0.3434 - val_acc: 0.8510\n",
      "Epoch 222/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3360 - acc: 0.8637 - val_loss: 0.3383 - val_acc: 0.8535\n",
      "Epoch 223/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3364 - acc: 0.8617 - val_loss: 0.3337 - val_acc: 0.8565\n",
      "Epoch 224/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3357 - acc: 0.8612 - val_loss: 0.3363 - val_acc: 0.8530\n",
      "Epoch 225/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3373 - acc: 0.8607 - val_loss: 0.3339 - val_acc: 0.8585\n",
      "Epoch 226/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3359 - acc: 0.8604 - val_loss: 0.3337 - val_acc: 0.8595\n",
      "Epoch 227/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3361 - acc: 0.8607 - val_loss: 0.3365 - val_acc: 0.8535\n",
      "Epoch 228/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3351 - acc: 0.8642 - val_loss: 0.3389 - val_acc: 0.8535\n",
      "Epoch 229/300\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3367 - acc: 0.8611 - val_loss: 0.3330 - val_acc: 0.8595\n",
      "Epoch 230/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3362 - acc: 0.8609 - val_loss: 0.3350 - val_acc: 0.8620\n",
      "Epoch 231/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3373 - acc: 0.8614 - val_loss: 0.3401 - val_acc: 0.8540\n",
      "Epoch 232/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3365 - acc: 0.8615 - val_loss: 0.3411 - val_acc: 0.8545\n",
      "Epoch 233/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3357 - acc: 0.8616 - val_loss: 0.3354 - val_acc: 0.8560\n",
      "Epoch 234/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3355 - acc: 0.8620 - val_loss: 0.3390 - val_acc: 0.8515\n",
      "Epoch 235/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3366 - acc: 0.8617 - val_loss: 0.3351 - val_acc: 0.8620\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3362 - acc: 0.8624 - val_loss: 0.3367 - val_acc: 0.8570\n",
      "Epoch 237/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3356 - acc: 0.8612 - val_loss: 0.3379 - val_acc: 0.8520\n",
      "Epoch 238/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3363 - acc: 0.8612 - val_loss: 0.3342 - val_acc: 0.8595\n",
      "Epoch 239/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3365 - acc: 0.8617 - val_loss: 0.3357 - val_acc: 0.8575\n",
      "Epoch 240/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3361 - acc: 0.8599 - val_loss: 0.3351 - val_acc: 0.8615\n",
      "Epoch 241/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3362 - acc: 0.8610 - val_loss: 0.3320 - val_acc: 0.8605\n",
      "Epoch 242/300\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3358 - acc: 0.8611 - val_loss: 0.3324 - val_acc: 0.8610\n",
      "Epoch 243/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3358 - acc: 0.8621 - val_loss: 0.3358 - val_acc: 0.8600\n",
      "Epoch 244/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3363 - acc: 0.8614 - val_loss: 0.3338 - val_acc: 0.8620\n",
      "Epoch 245/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3362 - acc: 0.8609 - val_loss: 0.3337 - val_acc: 0.8590\n",
      "Epoch 246/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3355 - acc: 0.8605 - val_loss: 0.3338 - val_acc: 0.8605\n",
      "Epoch 247/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3369 - acc: 0.8595 - val_loss: 0.3379 - val_acc: 0.8565\n",
      "Epoch 248/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3353 - acc: 0.8590 - val_loss: 0.3461 - val_acc: 0.8515\n",
      "Epoch 249/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3371 - acc: 0.8635 - val_loss: 0.3372 - val_acc: 0.8550\n",
      "Epoch 250/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3360 - acc: 0.8617 - val_loss: 0.3410 - val_acc: 0.8525\n",
      "Epoch 251/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3349 - acc: 0.8602 - val_loss: 0.3370 - val_acc: 0.8540\n",
      "Epoch 252/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3353 - acc: 0.8611 - val_loss: 0.3462 - val_acc: 0.8465\n",
      "Epoch 253/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3367 - acc: 0.8606 - val_loss: 0.3323 - val_acc: 0.8570\n",
      "Epoch 254/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3366 - acc: 0.8621 - val_loss: 0.3395 - val_acc: 0.8530\n",
      "Epoch 255/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3355 - acc: 0.8620 - val_loss: 0.3324 - val_acc: 0.8620\n",
      "Epoch 256/300\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3354 - acc: 0.8635 - val_loss: 0.3335 - val_acc: 0.8580\n",
      "Epoch 257/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3353 - acc: 0.8612 - val_loss: 0.3319 - val_acc: 0.8590\n",
      "Epoch 258/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3356 - acc: 0.8614 - val_loss: 0.3344 - val_acc: 0.8605\n",
      "Epoch 259/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3359 - acc: 0.8612 - val_loss: 0.3336 - val_acc: 0.8570\n",
      "Epoch 260/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3359 - acc: 0.8607 - val_loss: 0.3362 - val_acc: 0.8570\n",
      "Epoch 261/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3353 - acc: 0.8621 - val_loss: 0.3342 - val_acc: 0.8580\n",
      "Epoch 262/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3354 - acc: 0.8625 - val_loss: 0.3351 - val_acc: 0.8595\n",
      "Epoch 263/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3361 - acc: 0.8604 - val_loss: 0.3350 - val_acc: 0.8540\n",
      "Epoch 264/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3356 - acc: 0.8604 - val_loss: 0.3345 - val_acc: 0.8630\n",
      "Epoch 265/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3364 - acc: 0.8624 - val_loss: 0.3325 - val_acc: 0.8580\n",
      "Epoch 266/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3369 - acc: 0.8605 - val_loss: 0.3351 - val_acc: 0.8560\n",
      "Epoch 267/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3357 - acc: 0.8619 - val_loss: 0.3348 - val_acc: 0.8560\n",
      "Epoch 268/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3355 - acc: 0.8612 - val_loss: 0.3344 - val_acc: 0.8550\n",
      "Epoch 269/300\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3355 - acc: 0.8629 - val_loss: 0.3343 - val_acc: 0.8560\n",
      "Epoch 270/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3355 - acc: 0.8614 - val_loss: 0.3375 - val_acc: 0.8555\n",
      "Epoch 271/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3362 - acc: 0.8616 - val_loss: 0.3361 - val_acc: 0.8565\n",
      "Epoch 272/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3360 - acc: 0.8622 - val_loss: 0.3345 - val_acc: 0.8555\n",
      "Epoch 273/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3358 - acc: 0.8617 - val_loss: 0.3341 - val_acc: 0.8560\n",
      "Epoch 274/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3347 - acc: 0.8601 - val_loss: 0.3377 - val_acc: 0.8515\n",
      "Epoch 275/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3349 - acc: 0.8619 - val_loss: 0.3339 - val_acc: 0.8575\n",
      "Epoch 276/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3362 - acc: 0.8611 - val_loss: 0.3429 - val_acc: 0.8525\n",
      "Epoch 277/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3348 - acc: 0.8625 - val_loss: 0.3501 - val_acc: 0.8500\n",
      "Epoch 278/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3359 - acc: 0.8616 - val_loss: 0.3330 - val_acc: 0.8560\n",
      "Epoch 279/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3357 - acc: 0.8620 - val_loss: 0.3378 - val_acc: 0.8520\n",
      "Epoch 280/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3350 - acc: 0.8626 - val_loss: 0.3323 - val_acc: 0.8570\n",
      "Epoch 281/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3346 - acc: 0.8631 - val_loss: 0.3354 - val_acc: 0.8580\n",
      "Epoch 282/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3352 - acc: 0.8627 - val_loss: 0.3350 - val_acc: 0.8600\n",
      "Epoch 283/300\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3352 - acc: 0.8631 - val_loss: 0.3325 - val_acc: 0.8575\n",
      "Epoch 284/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3355 - acc: 0.8635 - val_loss: 0.3337 - val_acc: 0.8580\n",
      "Epoch 285/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3341 - acc: 0.860 - 0s 51us/step - loss: 0.3346 - acc: 0.8602 - val_loss: 0.3353 - val_acc: 0.8660\n",
      "Epoch 286/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3355 - acc: 0.8637 - val_loss: 0.3320 - val_acc: 0.8595\n",
      "Epoch 287/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3352 - acc: 0.8607 - val_loss: 0.3369 - val_acc: 0.8530\n",
      "Epoch 288/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3351 - acc: 0.8617 - val_loss: 0.3447 - val_acc: 0.8475\n",
      "Epoch 289/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3350 - acc: 0.8604 - val_loss: 0.3310 - val_acc: 0.8570\n",
      "Epoch 290/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3360 - acc: 0.8631 - val_loss: 0.3355 - val_acc: 0.8565\n",
      "Epoch 291/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3359 - acc: 0.8631 - val_loss: 0.3343 - val_acc: 0.8530\n",
      "Epoch 292/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3344 - acc: 0.8596 - val_loss: 0.3323 - val_acc: 0.8605\n",
      "Epoch 293/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3352 - acc: 0.8614 - val_loss: 0.3312 - val_acc: 0.8600\n",
      "Epoch 294/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3354 - acc: 0.8627 - val_loss: 0.3333 - val_acc: 0.8565\n",
      "Epoch 295/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3347 - acc: 0.8635 - val_loss: 0.3383 - val_acc: 0.8540\n",
      "Epoch 296/300\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3350 - acc: 0.8621 - val_loss: 0.3338 - val_acc: 0.8550\n",
      "Epoch 297/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3362 - acc: 0.8612 - val_loss: 0.3379 - val_acc: 0.8545\n",
      "Epoch 298/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3351 - acc: 0.8631 - val_loss: 0.3375 - val_acc: 0.8565A: 0s - loss: 0.3472 - acc: 0. - ETA: 0s - loss: 0.3344 - acc: 0.863\n",
      "Epoch 299/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3357 - acc: 0.8619 - val_loss: 0.3365 - val_acc: 0.8545\n",
      "Epoch 300/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3360 - acc: 0.8621 - val_loss: 0.3328 - val_acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "# Fitting ANN to the Training set\n",
    "h = classifier.fit(X_train, y_train, validation_data = (X_test, y_test), \n",
    "                   batch_size = 25, epochs = 300, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the loss\n",
    "plt.figure(1)\n",
    "plt.plot(h.history['loss'], label = 'loss')\n",
    "plt.plot(h.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the acc\n",
    "plt.figure(2)\n",
    "plt.plot(h.history['acc'], label = 'acc')\n",
    "plt.plot(h.history['val_acc'], label = 'val_acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def Classification(clf, X, y):\n",
    "    X_set, y_set = X, y\n",
    "    y_hat = clf.predict(X_set)\n",
    "    y_hat = np.reshape(y_hat, -1)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "    cm = confusion_matrix(y_set, y_hat)\n",
    "    accuracy = (cm[0, 0] + cm[1, 1])/cm.sum()\n",
    "    TPR = cm[0, 0]/cm[:, 0].sum() # Sensitivitive, Recall\n",
    "    TNR = cm[1, 1]/cm[:, 1].sum() # Specificitive\n",
    "    PPV = cm[0, 0]/cm[0, :].sum() # Positive Predictive Value, Precision\n",
    "    NPV = cm[1, 1]/cm[1, :].sum() # Negative Predictive Value,  \n",
    "    F1_score = 2/(1/PPV + 1/TPR)\n",
    "    summary = {'Accuracy': accuracy, \n",
    "               'Positive_Predictive_Value': PPV, \n",
    "               'Negative_Predictive_Value': NPV,            \n",
    "               'Sensitivitive': TPR, \n",
    "               'Specificitive': TNR,            \n",
    "               'F1_score': F1_score, \n",
    "               'CM': cm}\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.861375,\n",
       " 'Positive_Predictive_Value': 0.9693781407035176,\n",
       " 'Negative_Predictive_Value': 0.43995098039215685,\n",
       " 'Sensitivitive': 0.8710314660646253,\n",
       " 'Specificitive': 0.7864184008762322,\n",
       " 'F1_score': 0.9175771088814566,\n",
       " 'CM': array([[6173,  195],\n",
       "        [ 914,  718]], dtype=int64)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification(clf = classifier, X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.86,\n",
       " 'Positive_Predictive_Value': 0.9561128526645768,\n",
       " 'Negative_Predictive_Value': 0.48148148148148145,\n",
       " 'Sensitivitive': 0.8789625360230547,\n",
       " 'Specificitive': 0.7358490566037735,\n",
       " 'F1_score': 0.9159159159159157,\n",
       " 'CM': array([[1525,   70],\n",
       "        [ 210,  195]], dtype=int64)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification(clf = classifier, X = X_test, y = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 25, epochs = 300)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(accuracies, '-o')\n",
    "plt.axhline(accuracies.mean(), color = 'black', ls = '-')\n",
    "plt.axhline(accuracies.mean() + 2 * accuracies.std(), color = 'black', ls = '--')\n",
    "plt.axhline(accuracies.mean() - 2 * accuracies.std(), color = 'black', ls = '--')\n",
    "plt.xlabel('CV')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "print('ANN: CV score = %0.3f (+/- %0.3f)' % (accuracies.mean(), 2 * accuracies.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Evaluating, Improving and Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.5476 - acc: 0.7954\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.4351 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.4285 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.4247 - acc: 0.8001\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.4197 - acc: 0.8210\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.4149 - acc: 0.8289\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.4109 - acc: 0.8302\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4077 - acc: 0.8321\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.4057 - acc: 0.8315\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.4036 - acc: 0.8339\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.4024 - acc: 0.8351\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.4010 - acc: 0.8336\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.4001 - acc: 0.8370\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3993 - acc: 0.8360\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3985 - acc: 0.8357\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3978 - acc: 0.8362\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3970 - acc: 0.8379\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3967 - acc: 0.8347\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3964 - acc: 0.8364\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3958 - acc: 0.8359\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3954 - acc: 0.8382\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3948 - acc: 0.8370\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3937 - acc: 0.8359\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3928 - acc: 0.8372\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3913 - acc: 0.8405\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3899 - acc: 0.8395\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3863 - acc: 0.8405\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3837 - acc: 0.8415: 0s - loss: 0.3792 - acc: 0\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3803 - acc: 0.8431\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3764 - acc: 0.845 - 0s 42us/step - loss: 0.3765 - acc: 0.8444\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3720 - acc: 0.8461\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3685 - acc: 0.8452\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3641 - acc: 0.8494\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3614 - acc: 0.8491\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3593 - acc: 0.8510\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3567 - acc: 0.8550\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3552 - acc: 0.8520\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3540 - acc: 0.8550\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3522 - acc: 0.8534\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3512 - acc: 0.8562\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3500 - acc: 0.8562\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3485 - acc: 0.8545\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3482 - acc: 0.8565\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.3469 - acc: 0.8600\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3466 - acc: 0.8572\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3465 - acc: 0.8591\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3447 - acc: 0.8586\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3450 - acc: 0.8579\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3447 - acc: 0.8615\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3438 - acc: 0.8585\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3439 - acc: 0.8606\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3438 - acc: 0.8602\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3435 - acc: 0.8584\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3434 - acc: 0.8596\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3424 - acc: 0.8606\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3422 - acc: 0.8600\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3430 - acc: 0.8592\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3422 - acc: 0.8594\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3421 - acc: 0.8594\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3417 - acc: 0.8612\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3421 - acc: 0.8592\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3407 - acc: 0.8601\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3414 - acc: 0.8620\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3413 - acc: 0.8592\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3413 - acc: 0.8587\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3404 - acc: 0.8589\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3373 - acc: 0.863 - 0s 42us/step - loss: 0.3403 - acc: 0.8605\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3402 - acc: 0.8606: 0s - loss: 0.3527 - acc: 0.\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3410 - acc: 0.8590\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3397 - acc: 0.861 - 0s 41us/step - loss: 0.3396 - acc: 0.8617\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3405 - acc: 0.8604\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3394 - acc: 0.8601\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3396 - acc: 0.8617\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3393 - acc: 0.8604\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3397 - acc: 0.8591\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3392 - acc: 0.8610\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3388 - acc: 0.8605\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3397 - acc: 0.8591\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3382 - acc: 0.8621\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3387 - acc: 0.8602\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3383 - acc: 0.8619\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3381 - acc: 0.8599\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3383 - acc: 0.8605\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3383 - acc: 0.8604\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3375 - acc: 0.8627\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3382 - acc: 0.8589\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3388 - acc: 0.8617\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3373 - acc: 0.8616\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3378 - acc: 0.8605\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3381 - acc: 0.8601\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3378 - acc: 0.8594\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3381 - acc: 0.8620\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3378 - acc: 0.8614\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3379 - acc: 0.8607\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3381 - acc: 0.8635\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3385 - acc: 0.8606\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3383 - acc: 0.8599\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3383 - acc: 0.8611\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3369 - acc: 0.8610\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3370 - acc: 0.8596\n"
     ]
    }
   ],
   "source": [
    "# Improving the ANN\n",
    "# Dropout Regularization to reduce overfitting if needed\n",
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [25, 50], \n",
    "              'epochs': [300], \n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 0)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "results = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 25, 'epochs': 100, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
